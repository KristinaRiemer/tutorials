---
title: "Metadata Upload Tutorial Part 1: Additions"
author: "Kimberly Huynh"
date: "4/30/2019"
output: html_document
---

# Section 1: Overview

The objective of this tutorial is to demonstrate how to upload a season's metadata to the traits database.

Each season should have metadata for experiments, sites, treatments, cultivars, and citations.

For this tutorial, data will be uploaded to a test database. Instructions on how to set up a local instance of a test database can be found [here](https://gist.github.com/kimberlyh66/935106e35478829b9e844ba5b496784d).

This tutorial will only cover how to add new experiments, sites, treatments, cultivars, and citations. 

The `Metadata Upload Tutorial Part 2: Associations` tutorial should be viewed after completing this tutorial and when all new metadata have been added (see below for more details). The second tutorial will cover how to associate the metadata that you add.

# Section 2: Required input

URL to a public published google sheet (please provide in setup of section 3)

   * copy and fill out the following [google sheets template](https://docs.google.com/spreadsheets/d/1Fr_8xYOucyCQ9WH5_1bfPTMpm3IhKX5oqW4UOMvPoSY/edit?usp=sharing).
   * instructions on how to fill out the template can be found under the README worksheet.
   * make the google sheet public (to anyone with link) and publish to the web.

# Section 3: How to Run this Rmd

## Commit database transactions to upload data

Knitting this markdown file will not upload any data to the test database. Being able to knit this file means that you will be able to upload all of your new experiments, sites, treatments, cultivars, and citations metadata successfully.

To actually upload your data to the test database, you will need to make an edit to this markdown file. 

`commit = TRUE` needs to be set in calls to `addRow`. The value of `commit` needs to be changed from `FALSE` to `TRUE` in the following chunk:

```{r commit-param}

commit <- TRUE

```

NOTE: You will get errors if you try to insert your metadata more than once. 

If you would like to refresh the test database (remove additions that you have made), re-run step 3 of the `How to set up local instance of BETY test database` tutorial.

## Check uploaded data

You will not be able to fetch any of your uploaded data until it has been added to the database. You can check your uploaded results when you run this Rmd with `commit <- TRUE` in the above chunk:

```{r check-upload}

ifelse(commit == TRUE, eval_chk <- TRUE, eval_chk <- FALSE)

```

# Section 4: Metadata upload

## Set up

Please provide the URL to your google sheet below. 

A sample URL has been provided for a google sheet containing MAC season 8 metadata. Replace the sample URL with your own.

```{r url}

url <- 'https://docs.google.com/spreadsheets/d/1c_5j7q3TO6gQ24KSopE-_LXA5HhfsUEqMupckGZAbo8/edit#gid=0' 

```

The following packages will need to be loaded: `RPostgres`, `readxl`, `dplyr`, `googlesheets`, `kableExtra`, `glue`, and `DBI`

```{r load-pack, message = FALSE}

library(RPostgres)
library(readxl)
library(dplyr)
library(googlesheets)
library(kableExtra)
library(glue)
library(DBI)

```

Create database connection (make sure you have test database running). 

The port number should be the same as the one indicated in docker-compose.override.yml.

```{r create-dbcon}

# no password required 
dbcon <- dbConnect(RPostgres::Postgres(),
                   host = 'localhost',
                   user = 'bety',
                   port = 5433)

```

Functions to include in package

```{r pack-fx}

prepared_statement <- function(con, query, params) {
  stopifnot(
    class(con) == "PqConnection",
    is.character(query),
    length(query) == 1,
    is.list(params)
  )
  qry <- DBI::dbSendStatement(con, query)
  res <- DBI::dbBind(qry, params)
  on.exit(DBI::dbClearResult(res))
}

get_fields <- function(tbl_fields, row){
  com_ind <- which(!is.na(row))
  com_fields <- names(row)[com_ind]
  com_tbl_fields <- tbl_fields[tbl_fields %in% com_fields]
  return(com_tbl_fields)
}

get_params <- function(row, fields){
  params <- unname(as.list(row[fields]))
  return(params)
}

get_statement <- function(dbcon, tbl_name, fields){
  num_params <- length(fields)
  posit_params <- sapply(1:num_params, function(x) paste0('$', x))
  statement <- glue::glue_sql("insert into {DBI::SQL(tbl_name)}
                              ({DBI::SQL(paste(fields, collapse = ', '))})
                              values ({DBI::SQL(paste(posit_params, collapse = ', '))})",
                              .con = dbcon)
  return(statement)
}

add_specie <- function(species_to_add, dbcon, commit = FALSE){
  if(length(species_to_add) != 0){
    for(spp in species_to_add){
      DBI::dbBegin(dbcon)
      spp_insert <- glue::glue_sql("insert into species (scientificname) values ({spp})",
                                   .con = dbcon)
      ifelse(commit == TRUE, DBI::dbCommit(dbcon), DBI::dbRollback(dbcon))
    }
  }
}


add_row <- function(row, dbcon, tbl_name, tbl_fields, user_id = NULL, commit = FALSE){
  #user_id only required for experiment upload

  fields <- get_fields(tbl_fields, row)
  params <- get_params(row, fields)
  # extra addition needed to insert data into experiments
  if(tbl_name == 'experiments'){
    fields <- append(fields, 'user_id')
    params <- append(params, as.double(user_id)) #need to create this in experiments chunk
  }
  statement <- get_statement(dbcon, tbl_name, fields)
  DBI::dbBegin(dbcon)
  prepared_statement(dbcon, statement, params)
  ifelse(commit == TRUE, DBI::dbCommit(dbcon), DBI::dbRollback(dbcon))
}

associate_vals <- function(tbl_name, col_1, col_2, val_1, val_2, dbcon, commit = FALSE){
  statement <- glue::glue_sql("insert into {DBI::SQL(tbl_name)}
                              ({DBI::SQL(paste(c(col_1, col_2), collapse = ', '))})
                              values ($1, $2)",
                              .con = dbcon)
  params <- list(val_1, val_2)
  DBI::dbBegin(dbcon)
  prepared_statement(dbcon, statement, params)
  ifelse(commit == TRUE, DBI::dbCommit(dbcon), DBI::dbRollback(dbcon))
}

```

Read in metadata from google sheets. Each sheet of your google sheet will be read in directly as a R object.

```{r read-user-gs, message = FALSE}

# get key from URL
key <- extract_key_from_url(url)

# register sheet 
gs_obj <- key %>% gs_key(lookup = FALSE)

# users sheet
users <- gs_obj %>% gs_read(ws = 'users')

# experiments sheet
experiments <- gs_obj %>% gs_read(ws = 'experiments')

# sites sheet
sites <- gs_obj %>% gs_read(ws = 'sites')

# treatments sheet
treatments <- gs_obj %>% gs_read(ws = 'treatments')

# cultivars sheet
cultivars <- gs_obj %>% gs_read(ws = 'cultivars')

# citations sheet
citations <- gs_obj %>% gs_read(ws = 'citations')

```


## Upload data

### Step 1: Add new experiments

A user id will be needed to insert data into the experiments table. Your user id will be determined based on your provided user login (username for bety account). 

```{r add-exp}

bety_users <- tbl(dbcon, 'users') %>% collect()
 
user_id <- bety_users %>%
  filter(login == users$login) %>%
  select(id)

# get names of new experiments
new_exp <- experiments$name # assuming that each row of experiments sheet describes a unique experiment

# loop through new experiments
# filter for row with experiment name
# upload data for row using addRow
for(exp in new_exp){
  row <- experiments %>% filter(name == exp)
  add_row(row = row,
          dbcon = dbcon,
          commit = commit,
          tbl_name = 'experiments',
          tbl_fields = c('name', 'start_date', 'end_date',
                        'description', 'design'),
          user_id = user_id$id) #need to specify user_id since adding experiment
}

```

### Step 2: Add new sites

```{r add-site}

# get new site names
new_site <- sites$sitename # assuming that each row of sites sheet describes a unique site

# loop through new sitenames
# filter for row with sitename
# upload data for row using addRow
for(site in new_site){
  row <- sites %>% filter(sitename == site)
  add_row(row = row,
          dbcon = dbcon,
          commit = commit,
          tbl_name = 'sites',
          tbl_fields = c('city', 'state', 'country',
                         'notes', 'sitename', 'greenhouse',
                         'geometry', 'time_zone'))
}

```

### Step 3: Add new treatments

```{r add-treat}

# get new treatments
new_treat <- treatments$name # assuming that each row of treatments sheet describes a unique treatment

# loop through new treatments
# filter for row with treatment name
# upload data for row using addRow
for(treat in new_treat){
  row <- treatments %>% filter(name == treat)
  add_row(row = row,
          dbcon = dbcon,
          commit = commit,
          tbl_name = 'treatments',
          tbl_fields = c('name', 'defintion', 'control'))
}

```

### Step 4: Add new cultivars

Only rows that contain a combination of cultivar name and specie id that is not yet present in BETYdb will be uploaded.

First, we must make sure that all species present in cultivars sheet have been added to the BETY species table. 

If not, new records will be added to the species table. 

This needs to be done since specie ids in the cultivar table must reference an existing record in the species table.

```{r check-spp}

# refer to bety species table
bety_species <- tbl(dbcon, 'species') %>% collect()

# get unique species in cultivars
unq_spp <- unique(cultivars$species)

# get species to add
spp_to_add <- unq_spp[!unq_spp %in% bety_species$scientificname]

add_specie(commit = commit,
           species_to_add  = spp_to_add)

```

Now, create specie_id column in cultivars. The specie_id will be needed to add new records to the cultivars table.

```{r add-spp-id}

cultivars$specie_id <- vector('numeric', nrow(cultivars))

# get specie id from specie name
for(i in 1:nrow(cultivars)){
  sci_name <- cultivars$species[i]
  spp_id <- bety_species %>%
    filter(scientificname == sci_name) %>%
    select(id)
  cultivars$specie_id[i] <- as.double(spp_id$id)
}
  
```

Determine which combinations of cultivar name and species id should be uploaded to bety.

```{r get-new-cultivars}

# refer to bety cultivars table
bety_cultivars <- tbl(dbcon, 'cultivars') %>% 
  select(name, specie_id) %>%
  collect()

# want data type of specie_id columns in cultivars and bety_cultivars to be the same
bety_cultivars$specie_id <- as.double(bety_cultivars$specie_id)

# get subset of new cultivar + specie_id combinations
new_cultivars <- anti_join(cultivars[, c('name', 'specie_id')],   
                           bety_cultivars,
                           by = c('name', 'specie_id'))

```

Add new cultivars

```{r add-cultivar}

# loop through each row of new_cultivars
# upload data for row using addRow
for(i in 1:nrow(new_cultivars)){
  row <- new_cultivars %>% slice(i)
  add_row(row = row,
          dbcon = dbcon,
          commit = commit,
          tbl_name = 'cultivars',
          tbl_fields = c('name', 'specie_id', 'ecotype', 'notes'))
}

```

### Step 5: Add new citation

```{r add-citation}

# loop through each row of citations
# upload data for row using addRow

for(i in 1:nrow(citations)){
  row <- citations %>% slice(i)
  add_row(row = row,
          dbcon = dbcon,
          commit = commit,
          tbl_name = 'citations',
          tbl_fields = c('author', 'year', 'title',
                         'journal', 'volume', 'page',
                         'url', 'pdf', 'doi'))
}

```

## Check data upload

Fetch experiments

```{r fetch-exp, eval = eval_chk}

exp_query <- dbSendQuery(dbcon,
                         glue_sql("select * from experiments where name in ({new_exp*})",
                                  .con = dbcon))

exp_fetch <- dbFetch(exp_query)
dbClearResult(exp_query)

kable(exp_fetch) %>%
  kable_styling(latex_options = c('scale_down'))


```


Close database connection

```{r close-dbcon}
dbDisconnect(dbcon)
```
